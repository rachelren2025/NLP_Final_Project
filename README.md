# NLP_Final_Project
Natural Language Processing (NLP) models play a critical role in automating complex text-based tasks, including applications in specialized fields like legal informatics. This paper investigates the use of NLP for legal case analysis utilizing large language models (LLM) and evaluating them for their effectiveness in processing legal texts. Multiple evaluation metrics are used to assess the models' performance in accurately interpreting and answering these questions. In the domain-specific field, Legal Question Answering (LQA), correctness is especially valued as there are greater repercussions of incorrect choices. We ran three models, BERT-double, Legal-BERT, and Custom-legal BERT. Instead of using traditional metrics to measure how well each model performs on legal multiple choice questions and answering, we propose a novel metric that incorporates question difficulty, model confidence, and correctness to calculate a more comprehensive score.

The specifics of how we implemented our tasks are written in our final paper titled, "Evaluating Large Language Models for Legal Multiple Choice Question and Answering"
