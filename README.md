# NLP Final Project (Python)
New York University – College of Arts and Science
## Course Context
This repository contains the group final project for Natural Language Processing at NYU. Our team focused on applying NLP to the domain of legal informatics, specifically evaluating large language models (LLMs) for legal case analysis and question answering. The work emphasized both standard NLP workflows—preprocessing, feature engineering, model training—and domain-specific challenges where correctness has heightened importance due to real-world legal consequences.

**Tech Stack**: Python · NLTK · NumPy · Pandas · Jupyter · Transformers

## Project Highlights
- **Domain-specific task** — Applied NLP methods to Legal Question Answering (LQA), where accuracy and reliability are critical.
- **Model Comparison** — Trained and evaluated BERT-Double, Legal-BERT, and a Custom-Legal BERT model.
- **Novel Metric** — Proposed a new evaluation framework that integrates question difficulty, model confidence, and correctness, providing a more comprehensive performance measure than traditional metrics alone.
- **Standard Benchmarks** — Evaluated models using accuracy, precision, recall, and F1-score for comparability.
- **Research Output** — Findings are documented in the paper Evaluating Large Language Models for Legal Multiple Choice Question and Answering *(https://drive.google.com/file/d/1SlIB_rnTibULa-J41kgCeESV4NL8bHfY/view?usp=sharing)*.

## Skills Developed
- Applying transformer-based models to specialized, domain-specific NLP problems.
- Designing and implementing custom evaluation metrics to capture nuances beyond standard benchmarks.
- Conducting rigorous model comparison across baseline and fine-tuned LLMs.
- Managing end-to-end NLP pipelines, from text preprocessing to final evaluation.
- Communicating technical findings in a structured research paper format.
